# Legal Eagle ğŸ¦…

## ğŸ‘¥ NLP Team Project - Team 7 ğŸ‘¥ - BoMin LEE, Jeonhui LEE, Chanwoo LIM, Hyeongbin SEO, Sebin JEONG


### Transformers
-    BitsAndBytesConfig: modelì˜ bit formatì„ ì„ì˜ë¡œ ì§€ì •í•˜ì—¬ í° gpu ìì›ì´ í•„ìš”ì¹˜ ì•Šë„ë¡ í•¨. í•´ë‹¹ ëª¨ë¸ì—ì„œëŠ” NF4(ì •ê·œí™”ëœ ë¶€ë™ ì†Œìˆ˜ì ) ì–‘ìí™”ë¥¼ ì‚¬ìš©í•˜ê³ , dtypeì„ float16ìœ¼ë¡œ ì§€ì •í•˜ì—¬ ê³„ì‚°ì´ ë¹ ë¥´ê²Œ ì§„í–‰ë˜ë„ë¡ í•¨.
-    AutoModelForCausalLM: ê²½ë¡œë‚˜ urlì„ ì§€ì •í•˜ì—¬ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ”ë° ì‚¬ìš©ë¨.
-    AutoTokenizer: í•´ë‹¹ ëª¨ë¸ì˜ tokenizer
-    TrainingArguments: trainingì— í•„ìš”í•œ argumentsë¥¼ ì§€ì •

### Peft
-    Parameter-Efficient Fine-Tuning ì†Œìˆ˜ì˜ ëª¨ë¸ íŒŒë¼ë¯¸í„°ë¥¼ fine tuning í•¨ìœ¼ë¡œ íš¨ìœ¨ì  ë° ì ì€ ì»´í“¨íŒ… ìì›ìœ¼ë¡œ fine tuningì´ ê°€ëŠ¥í•´ì§. Loar, Prefix Tuning, P-Tuning ë“± ì´ëŸ¬í•œ ê¸°ë²•ë“¤ì„ ì‰½ê²Œ ì‚¬ìš©í•˜ê²Œ í•´ì£¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, í•´ë‹¹ ëª¨ë¸ì—ëŠ” Loar ê¸°ë²•ì„ ì‚¬ìš©í•¨.

### Trl
-    Trlì€ transformer ê°•í™” í•™ìŠµì„ ì œê³µí•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ í•´ë‹¹ ëª¨ë¸ì—ì„œëŠ” SFTTrainer(Supervised fine-tuning)ë¥¼ ì´ìš©.


<!--

**Here are some ideas to get you started:**

ğŸ™‹â€â™€ï¸ A short introduction - what is your organization all about?
ğŸŒˆ Contribution guidelines - how can the community get involved?
ğŸ‘©â€ğŸ’» Useful resources - where can the community find your docs? Is there anything else the community should know?
ğŸ¿ Fun facts - what does your team eat for breakfast?
ğŸ§™ Remember, you can do mighty things with the power of [Markdown](https://docs.github.com/github/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax)
-->
